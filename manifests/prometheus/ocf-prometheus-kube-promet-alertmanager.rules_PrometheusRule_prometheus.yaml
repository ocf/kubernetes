apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: kube-prometheus-stack
    app.kubernetes.io/instance: ocf-prometheus
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: kube-prometheus-stack
    app.kubernetes.io/version: 16.0.1
    chart: kube-prometheus-stack-16.0.1
    heritage: Helm
    release: ocf-prometheus
  name: ocf-prometheus-kube-promet-alertmanager.rules
  namespace: prometheus
spec:
  groups:
  - name: alertmanager.rules
    rules:
    - alert: AlertmanagerConfigInconsistent
      annotations:
        message: 'The configuration of the instances of the Alertmanager cluster `{{
          $labels.namespace }}/{{ $labels.service }}` are out of sync.

          {{ range printf "alertmanager_config_hash{namespace=\"%s\",service=\"%s\"}"
          $labels.namespace $labels.service | query }}

          Configuration hash for pod {{ .Labels.pod }} is "{{ printf "%.f" .Value
          }}"

          {{ end }}

          '
      expr: count by(namespace,service) (count_values by(namespace,service) ("config_hash",
        alertmanager_config_hash{job="ocf-prometheus-kube-promet-alertmanager",namespace="prometheus"}))
        != 1
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerFailedReload
      annotations:
        message: Reloading Alertmanager's configuration has failed for {{ $labels.namespace
          }}/{{ $labels.pod}}.
      expr: alertmanager_config_last_reload_successful{job="ocf-prometheus-kube-promet-alertmanager",namespace="prometheus"}
        == 0
      for: 10m
      labels:
        severity: warning
    - alert: AlertmanagerMembersInconsistent
      annotations:
        message: Alertmanager has not found all other members of the cluster.
      expr: "alertmanager_cluster_members{job=\"ocf-prometheus-kube-promet-alertmanager\"\
        ,namespace=\"prometheus\"}\n  != on (service) GROUP_LEFT()\ncount by (service)\
        \ (alertmanager_cluster_members{job=\"ocf-prometheus-kube-promet-alertmanager\"\
        ,namespace=\"prometheus\"})"
      for: 5m
      labels:
        severity: critical
